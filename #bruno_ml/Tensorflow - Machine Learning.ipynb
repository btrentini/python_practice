{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T22:17:20.128888Z",
     "start_time": "2018-09-22T22:15:49.268285Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 17s 277us/step - loss: 0.2184 - acc: 0.9348\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0963 - acc: 0.9708\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0687 - acc: 0.9783\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0547 - acc: 0.9822\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0428 - acc: 0.9861\n",
      "10000/10000 [==============================] - 0s 49us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06262970131516922, 0.9813]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T22:21:56.614021Z",
     "start_time": "2018-09-22T22:21:20.496379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-b3828aebc9c9>:1: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From D:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From D:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "data = tf.contrib.learn.datasets.mnist.load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T22:22:38.050877Z",
     "start_time": "2018-09-22T22:22:37.536410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_input_fn(dataset_split, batch_size, capacity=10000, min_after_dequeue=3000):\n",
    "\n",
    "  def _input_fn():\n",
    "    images_batch, labels_batch = tf.train.shuffle_batch(\n",
    "        tensors=[dataset_split.images, dataset_split.labels.astype(np.int32)],\n",
    "        batch_size=batch_size,\n",
    "        capacity=capacity,\n",
    "        min_after_dequeue=min_after_dequeue,\n",
    "        enqueue_many=True,\n",
    "        num_threads=4)\n",
    "    features_map = {'images': images_batch}\n",
    "    return features_map, labels_batch\n",
    "\n",
    "  return _input_fn\n",
    "\n",
    "data = tf.contrib.learn.datasets.mnist.load_mnist()\n",
    "\n",
    "train_input_fn = get_input_fn(data.train, batch_size=256)\n",
    "eval_input_fn = get_input_fn(data.validation, batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T22:22:57.449887Z",
     "start_time": "2018-09-22T22:22:57.446879Z"
    }
   },
   "outputs": [],
   "source": [
    "image_column = tf.contrib.layers.real_valued_column('images', dimension=784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T22:24:18.424427Z",
     "start_time": "2018-09-22T22:23:00.939962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\bruno\\AppData\\Local\\Temp\\tmpndzf0t91\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000146359894A8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\bruno\\\\AppData\\\\Local\\\\Temp\\\\tmpndzf0t91'}\n",
      "WARNING:tensorflow:From D:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\bruno\\AppData\\Local\\Temp\\tmpndzf0t91\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3025854, step = 0\n",
      "INFO:tensorflow:global_step/sec: 219.699\n",
      "INFO:tensorflow:loss = 0.37379068, step = 100 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.424\n",
      "INFO:tensorflow:loss = 0.38534775, step = 200 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.51\n",
      "INFO:tensorflow:loss = 0.3641888, step = 300 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.096\n",
      "INFO:tensorflow:loss = 0.26806355, step = 400 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.299\n",
      "INFO:tensorflow:loss = 0.37598377, step = 500 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.376\n",
      "INFO:tensorflow:loss = 0.261331, step = 600 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.625\n",
      "INFO:tensorflow:loss = 0.36230752, step = 700 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.905\n",
      "INFO:tensorflow:loss = 0.23066536, step = 800 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.492\n",
      "INFO:tensorflow:loss = 0.30138814, step = 900 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.589\n",
      "INFO:tensorflow:loss = 0.28990278, step = 1000 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.088\n",
      "INFO:tensorflow:loss = 0.35605055, step = 1100 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.515\n",
      "INFO:tensorflow:loss = 0.283481, step = 1200 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.581\n",
      "INFO:tensorflow:loss = 0.3910617, step = 1300 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.037\n",
      "INFO:tensorflow:loss = 0.27672964, step = 1400 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.118\n",
      "INFO:tensorflow:loss = 0.2145412, step = 1500 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.906\n",
      "INFO:tensorflow:loss = 0.30442166, step = 1600 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.428\n",
      "INFO:tensorflow:loss = 0.36081916, step = 1700 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.837\n",
      "INFO:tensorflow:loss = 0.36398458, step = 1800 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.191\n",
      "INFO:tensorflow:loss = 0.26215574, step = 1900 (0.275 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\bruno\\AppData\\Local\\Temp\\tmpndzf0t91\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.26201424.\n",
      "Elapsed time: 74.49000883102417 seconds\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-22-22:24:15\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\bruno\\AppData\\Local\\Temp\\tmpndzf0t91\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-22-22:24:17\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9254, global_step = 2000, loss = 0.27582672\n",
      "{'loss': 0.27582672, 'accuracy': 0.9254, 'global_step': 2000}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Specify the feature(s) to be used by the estimator.\n",
    "image_column = tf.contrib.layers.real_valued_column('images', dimension=784)\n",
    "estimator = tf.contrib.learn.LinearClassifier(feature_columns=[image_column], n_classes=10)\n",
    "\n",
    "# Train.\n",
    "start = time.time()\n",
    "estimator.fit(input_fn=train_input_fn, steps=2000)\n",
    "end = time.time()\n",
    "print('Elapsed time: {} seconds'.format(end - start))\n",
    "\n",
    "# Evaluate and report metrics.\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn, steps=1)\n",
    "print(eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T22:24:40.189616Z",
     "start_time": "2018-09-22T22:24:40.177474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\bruno\\AppData\\Local\\Temp\\tmpsaa6_rup\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000146359ED6D8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\bruno\\\\AppData\\\\Local\\\\Temp\\\\tmpsaa6_rup'}\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.FtrlOptimizer(learning_rate=5.0, l2_regularization_strength=1.0)\n",
    "estimator = tf.contrib.learn.LinearClassifier(\n",
    "    feature_columns=[image_column], n_classes=10, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
